{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "one shot test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNkW4l+dc4JMvVm52WqU6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharbiswas10/One-Shot-Siamese-Network/blob/main/one_shot_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dff6bUC2BLxU",
        "outputId": "e14dbe0b-79f7-4b4b-a741-e075a8790b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#!pip install keras-facenet\n",
        "#!pip install keras\n",
        "#!pip install tensorflow\n",
        "import pickle\n",
        "import cv2\n",
        "import os.path\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.layers import Layer\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def converter(ip,model):\n",
        "    pic = cv2.imread(ip, 1)\n",
        "    img1 = cv2.resize(pic, (160,160))\n",
        "    xt = np.array([img1])\n",
        "    embedding = model.predict_on_batch(xt)\n",
        "    return embedding\n",
        "\n",
        "    return code\n",
        "\n",
        "\n",
        "data = (3, 160, 160)\n",
        "paths=\"/content/drive/MyDrive/img\"\n",
        "#\n",
        "faces = []\n",
        "\n",
        "images = {}\n",
        "\n",
        "\n",
        "def refactor(batch_size=16):\n",
        "    y = np.zeros((batch_size, 2, 1))\n",
        "    \n",
        "    positives = np.zeros((batch_size, data[0], data[1], data[2]))\n",
        "    base = np.zeros((batch_size, data[0], data[1], data[2]))\n",
        "    negatives = np.zeros((batch_size, data[0], data[1], data[2]))\n",
        "\n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            positiveFace = faces[np.random.randint(len(faces))]\n",
        "            negativeFace = faces[np.random.randint(len(faces))]\n",
        "            while positiveFace == negativeFace:\n",
        "                negativeFace = faces[np.random.randint(len(faces))]\n",
        "\n",
        "            positives[i] = images[positiveFace][np.random.randint(len(images[positiveFace]))]\n",
        "            base[i] = images[positiveFace][np.random.randint(len(images[positiveFace]))]\n",
        "            negatives[i] = images[negativeFace][np.random.randint(len(images[negativeFace]))]\n",
        "\n",
        "        x_data = {'anchor': base,\n",
        "                  'anchorPositive': positives,\n",
        "                  'anchorNegative': negatives\n",
        "                  }\n",
        "\n",
        "        yield (x_data, [y, y, y])"
      ],
      "metadata": {
        "id": "FL07T239CUBr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refactor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqUgCoHpD3ZF",
        "outputId": "60a1277d-1af3-4c1a-99a4-04169d9edd6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object refactor at 0x7f44af9c4250>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "    pos_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[1])) )\n",
        "    neg_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[2])) )\n",
        "    basic_loss = pos_dist - neg_dist + alpha\n",
        "    loss = tf.maximum(basic_loss, 0.0)\n",
        "   \n",
        "    return loss"
      ],
      "metadata": {
        "id": "RUlk72fACgY8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "fModel = load_model('/content/drive/MyDrive/model/facenet_keras.h5', custom_objects={'triplet_loss': triplet_loss})\n",
        "fModel.compile(loss=triplet_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CK5iNNaCovV",
        "outputId": "0932df3a-18aa-4ce7-a7b2-9b77199c9c39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the user database\n",
        "def dbManager():\n",
        "    # check for existing database\n",
        "    if os.path.exists('database/uDb.pickle'):\n",
        "        with open('database/uDb.pickle', 'rb') as handle:\n",
        "            db = pickle.load(handle)   \n",
        "    else:\n",
        "        # make a new one\n",
        "        # we use a dict for keeping track of mapping of each person with his/her face encoding\n",
        "        db = {}\n",
        "        # create the directory for saving the db pickle file\n",
        "        os.makedirs('database',exist_ok=True)\n",
        "        with open('database/uDb.pickle', 'wb') as handle:\n",
        "            pickle.dump(db, handle, protocol=pickle.HIGHEST_PROTOCOL)   \n",
        "    return db"
      ],
      "metadata": {
        "id": "LBJY1ifnCrQL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adds a new user face to the database using his/her image stored on disk using the image path\n",
        "def addImg(db,fModel,  name, img_path):\n",
        "    if name not in db: \n",
        "        db[name] = converter(img_path,fModel)\n",
        "        print(\"Encodings:\",db[name])\n",
        "        # save the database\n",
        "        with open('database/uDb.pickle', 'wb') as handle:\n",
        "                pickle.dump(db, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print('User ' + name + ' is added')\n",
        "    else:\n",
        "        print('This name is already in database.')"
      ],
      "metadata": {
        "id": "HuAIDLz_Cue7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we use a dict for keeping track of mapping of each person with his/her face encoding\n",
        "db = dbManager()"
      ],
      "metadata": {
        "id": "qB1gcVXnCx_D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recognize the input user face encoding by checking for it in the database\n",
        "def look_up(image_path, database, model, threshold = 0.6):\n",
        "    # find the face encodings for the input image\n",
        "    print(image_path)\n",
        "    encoding = converter(image_path,model)\n",
        "    \n",
        "    min_dist = 99999\n",
        "    # loop over all the recorded encodings in database \n",
        "    for name in database:\n",
        "        # find the similarity between the input encodings and claimed person's encodings using L2 norm\n",
        "        dist = np.linalg.norm(np.subtract(database[name], encoding) )\n",
        "        # check if minimum distance or not\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    print( \"Identity:\",identity)\n",
        "    \n",
        "        \n",
        "    return min_dist, identity"
      ],
      "metadata": {
        "id": "3YYdnTYzC1Nc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes an input image and performs face recognition on it\n",
        "def getFace(db, fModel, threshold = 0.7, img_loc = \"/content/drive/MyDrive/saved_image/temp.jpg\"):\n",
        "    # resize the image\n",
        "    img = cv2.imread(img_loc, 1)\n",
        "    img = cv2.resize(img, (96, 96))\n",
        "    # save the temporary image\n",
        "    cv2.imwrite(\"/content/drive/MyDrive/saved_image/temp.jpg\", img)\n",
        "\n",
        "    look_up(\"/content/drive/MyDrive/saved_image/temp.jpg\", db, fModel, threshold)"
      ],
      "metadata": {
        "id": "zcGpZ3OzC4Yz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addImg(db,fModel, \"rock\", \"/content/drive/MyDrive/sample pic/rock.jpg\")\n",
        "addImg(db,fModel,  \"sab\", \"/content/drive/MyDrive/sample pic/sab.JPG\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHzL5haOC-fE",
        "outputId": "8262f13c-adcd-4ba1-e0cd-4e3ebd7f9477"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This name is already in database.\n",
            "This name is already in database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recognize the input user face encoding by checking for it in the database\n",
        "def look_up(image_path, database, model, threshold = 0.6):\n",
        "    # find the face encodings for the input image\n",
        "    print(image_path)\n",
        "    encoding = converter(image_path,model)\n",
        "    \n",
        "    min_dist = 99999\n",
        "    # loop over all the recorded encodings in database \n",
        "    for name in database:\n",
        "        # find the similarity between the input encodings and claimed person's encodings using L2 norm\n",
        "        dist = np.linalg.norm(np.subtract(database[name], encoding) )\n",
        "        # check if minimum distance or not\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    print( \"Identity:\",identity)\n",
        "    \n",
        "        \n",
        "    return min_dist, identity"
      ],
      "metadata": {
        "id": "j9_JwGh2DA1M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes an input image and performs face recognition on it\n",
        "def getFace(db, fModel, threshold = 0.7, img_loc = \"/content/drive/MyDrive/saved_image/temp.jpg\"):\n",
        "    # resize the image\n",
        "    img = cv2.imread(img_loc, 1)\n",
        "    img = cv2.resize(img, (96, 96))\n",
        "    # save the temporary image\n",
        "    cv2.imwrite(\"/content/drive/MyDrive/saved_image/temp.jpg\", img)\n",
        "\n",
        "    look_up(\"/content/drive/MyDrive/saved_image/temp.jpg\", db, fModel, threshold)"
      ],
      "metadata": {
        "id": "v9_PGV44DDSL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getFace(db,fModel,  threshold = 0.7, img_loc = \"/content/drive/MyDrive/sample pic/john-cena.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRPQZQ2pDGAj",
        "outputId": "681477e1-550a-4100-f28d-a160a20e7bbf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/saved_image/temp.jpg\n",
            "Identity: rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getFace(db, fModel, threshold = 0.7, img_loc = \"/content/drive/MyDrive/sample pic/rock2.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9u3oGa_pUz6",
        "outputId": "e6da89aa-dedc-4550-c9da-33a3ad60e91d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/saved_image/temp.jpg\n",
            "Identity: rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getFace(db, fModel, threshold = 0.7, img_loc = \"/content/drive/MyDrive/sample pic/shahin.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO5Vgl9ZstBK",
        "outputId": "1233ed5a-a3a5-4063-fb0a-8927b1441520"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/saved_image/temp.jpg\n",
            "Identity: rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c62aFn2ctFaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}